{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.386969300Z",
     "start_time": "2024-04-18T07:51:04.906508900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Suppress DtypeWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.410470100Z",
     "start_time": "2024-04-18T07:51:06.389063200Z"
    }
   },
   "id": "f46a516807c173b0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Root of project\n",
    "root_dir = os.path.join(\"analysis_data\")\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "# Raw data from api\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Formatted CSV data\n",
    "csv_dir = os.path.join(root_dir, \"csv\")\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# Data split by location\n",
    "location_dir = os.path.join(root_dir, \"location\")\n",
    "os.makedirs(location_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.429477Z",
     "start_time": "2024-04-18T07:51:06.395579600Z"
    }
   },
   "id": "53630421909da6db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(start: str, end: str):\n",
    "    data = requests.get(\n",
    "        f\"https://ilm2.site.dustmonitoring.nl/download?from={start}&to={end}&interval=600&align=1&type=csv-semicolon&p=531&p=521&p=542&p=543&p=553&p=544&p=545&p=532&p=533&p=554&p=534&p=535&p=546&p=536&p=556&p=522&p=557&p=547&p=549&p=524&p=537&p=525&p=526&p=539&p=551&p=540&p=558&p=527&p=528&p=529&p=530&p=560&p=561&p=562&p=563&p=564&p=565&p=566&p=567&p=568&p=569&p=570&p=571&p=574&p=575&p=576&p=577&p=578&s=10&s=11&s=128&s=129&s=130&s=145&s=146\"\n",
    "    )\n",
    "    return data.text\n",
    "\n",
    "_date = date(2020, 11, 1)\n",
    "\n",
    "while True:\n",
    "    start_date = _date\n",
    "    end_date = _date + relativedelta(months=2)\n",
    "    data = get_data(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    file_path = os.path.join(data_dir, f\"data_{start_date.strftime('%Y-%m-%d')}.csv\")\n",
    "\n",
    "    with open(file_path, \"+w\") as file:\n",
    "        file.write(data)\n",
    "\n",
    "    _date = end_date\n",
    "    if _date > date(2024, 3, 1):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-18T07:51:06.410470100Z"
    }
   },
   "id": "3fa428b6a93ea1b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir(data_dir):\n",
    "\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "    df = pd.read_csv(file_path, index_col=False, sep=\";\")\n",
    "\n",
    "    # Get the values of the first 2 rows\n",
    "    header_string = df.iloc[:2].values\n",
    "    row_1 = [row.split(\".\")[0] for row in df.columns.tolist()]\n",
    "    row_2 = header_string[0]\n",
    "\n",
    "    # Merge these into the new column names\n",
    "    new_columns = []\n",
    "    for row1, row2 in zip(row_1, row_2):\n",
    "        row1 = row1.replace(\"Unnamed: \", \"\")\n",
    "        new_columns.append(f\"{row1}-{row2}\")\n",
    "    # Remove the used rows\n",
    "    df = df.iloc[2:]\n",
    "    # Set new column names\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    csv_file_path = os.path.join(csv_dir, file)\n",
    "    df.to_csv(csv_file_path, index=False, index_label=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a90206e45f939dd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get all monthly datasets\n",
    "dfs = []\n",
    "for file in os.listdir(csv_dir):\n",
    "    csv_file_path = os.path.join(csv_dir, file)\n",
    "    df = pd.read_csv(csv_file_path, index_col=False)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Join datasets togather into one\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c15764efb671e3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for location in range(1, 60):\n",
    "    location = str(location)\n",
    "    if len(location) < 2:\n",
    "        location = '0' + location\n",
    "    \n",
    "    location_columns = ['0-Tijd', '1-Tijd']\n",
    "    for column in df.columns:\n",
    "        if location in column:\n",
    "            location_columns.append(column)\n",
    "\n",
    "    if len(location_columns) > 2:\n",
    "        df_temp = df[location_columns]\n",
    "        location_csv_path = os.path.join(location_dir, f\"I{location}.csv\")\n",
    "        df_temp.to_csv(location_csv_path, index=False, index_label=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "865e070d91ef0845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []\n",
    "for location in range(1, 60):\n",
    "    location = str(location)\n",
    "    if len(location) < 2:\n",
    "        location = '0' + location\n",
    "    location_csv_path = os.path.join(location_dir, f\"I{location}.csv\")\n",
    "    if not os.path.isfile(location_csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(location_csv_path)\n",
    "    df = df.iloc[df[df.columns[2]].first_valid_index():]\n",
    "    df = df.iloc[:df[df.columns[2]].last_valid_index()]\n",
    "\n",
    "    total = df.shape[0]\n",
    "    missing = df[df.columns[2]].isnull().sum()\n",
    "    perc = round(missing/total*100, 2)\n",
    "\n",
    "    obj = {\n",
    "        \"location\": location,\n",
    "        \"start\": df[\"0-Tijd\"][df[\"0-Tijd\"].first_valid_index()],\n",
    "        \"end\": df[\"0-Tijd\"][df[\"0-Tijd\"].last_valid_index()],\n",
    "        \"total rows\": total,\n",
    "        \"missing rows\": missing,\n",
    "        \"percentage missing\": f\"{round(perc, 2)} %\"\n",
    "    }\n",
    "    results.append(obj)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c72a2d4b6ea25759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_records(results)\n",
    "df_res"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e215bdce6214d4f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
